{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"E:\\data\\trian\"\n",
    "img_size=256             \n",
    "counter=0            \n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=os.listdir(data_path)\n",
    "\n",
    "for category in categories:                                                            # this loop to know how many images in categories\n",
    "    folder_path=os.path.join(data_path,category)                                       # make folder empty has the same path for dataset\n",
    "    img_names=os.listdir(folder_path)                                                  # put each image in this folder\n",
    "\n",
    "    for img_name in img_names:\n",
    "        img_path=os.path.join(folder_path,img_name)\n",
    "        fullpath=os.path.join(data_path,category,img_name)\n",
    "        try:\n",
    "            img = cv2.imread(fullpath, cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (img_size,img_size))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            X.append(img)\n",
    "            Y.append(category)\n",
    "            counter+=1\n",
    "            print(\"Reprocessing Image Number: \",counter)\n",
    "        except:\n",
    "            print(\"Error in ==> \",counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=np.array(X)\n",
    "lbls=np.array(Y)\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(lbls)\n",
    "lbls_encoded = le.transform(lbls)\n",
    "\n",
    "#Train and Test Split\n",
    "train_x, test_x,train_y, test_y = train_test_split(imgs,lbls_encoded,test_size=0.1)\n",
    "\n",
    "#Normalization\n",
    "train_x, test_x = train_x / 255.0,  test_x / 255.0\n",
    "\n",
    "#One Hot Encoding\n",
    "y_train_one_hot = to_categorical(train_y)\n",
    "y_test_one_hot = to_categorical(test_y)\n",
    "\n",
    "#Feature Extraction\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size,img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "VGG_model.summary()  \n",
    "feature_extractor=VGG_model.predict(train_x)\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "X_for_RF_DT = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Training\n",
    "RF_model = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "RF_model.fit(X_for_RF_DT, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Training (Has Less Accuracy)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_model= DecisionTreeClassifier(criterion='gini',max_depth=200,random_state = 0) \n",
    "DT_model.fit(X_for_RF_DT, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "###########\n",
    "\n",
    "#Feature Extraction For Test Data\n",
    "feature_extractor_test=VGG_model.predict(test_x)\n",
    "features_test = feature_extractor_test.reshape(feature_extractor_test.shape[0], -1)\n",
    "\n",
    "#Prediction using trained RF\n",
    "prediction_RF = RF_model.predict(features_test)\n",
    "prediction_RF_Normal = le.inverse_transform(prediction_RF)\n",
    "\n",
    "#Prediction using trained DT (Has Less Accuracy)\n",
    "prediction_DT = DT_model.predict(features_test)\n",
    "prediction_DT_Normal = le.inverse_transform(prediction_DT)\n",
    "\n",
    "test_y_Normal = le.inverse_transform(test_y)\n",
    "print (\"Accuracy Using Random Forest = \", metrics.accuracy_score(test_y_Normal, prediction_RF_Normal)*100,\"%\")\n",
    "print (\"Accuracy Using Decision Trees = \", metrics.accuracy_score(test_y_Normal, prediction_DT_Normal)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Plotting Confusion Matrix ############ \n",
    "y_pred = RF_model.predict(features_test)\n",
    "confusion_matrix= confusion_matrix(test_y, y_pred)\n",
    "print(confusion_matrix)\n",
    "ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues')\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['0','1','2','3','4','5'])\n",
    "ax.yaxis.set_ticklabels(['0','1','2','3','4','5'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GUI Part #####\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter.filedialog import askopenfile\n",
    "from PIL import Image, ImageTk\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1500x1050\")  # Size of the window \n",
    "root.resizable(width=False, height=False)\n",
    "root.title('Object Detector')\n",
    "root['background']='#222227' \n",
    "my_font1=('times', 18, 'bold')\n",
    "my_font2=('times', 12, 'bold')\n",
    "label = tk.Label(root,text='Upload Files & Detect',width=30,font=my_font1)\n",
    "label.grid(row=1,column=1)\n",
    "label.place(anchor = CENTER, relx = .5, rely = .025)\n",
    "b1 = tk.Button(root, text='Upload Images', width=20,command = lambda:upload_file())\n",
    "b1.grid(row=2,column=1,pady=5)\n",
    "b1.place(anchor = CENTER, relx = .5, rely = .070)\n",
    "def upload_file():\n",
    "    f_types = [('Jpg Files', '*.jpg'),\n",
    "    ('PNG Files','*.png'),('Jpeg Files', '*.jpeg')]   # types of files to select \n",
    "    filename = tk.filedialog.askopenfilename(multiple=True,filetypes=f_types)\n",
    "    col=1 # start from column 1\n",
    "    row=3 # start from row 3 \n",
    "    for pathgui in filename:\n",
    "        img=Image.open(pathgui)# read the image file\n",
    "        list_of_images = []\n",
    "        img_preprocessed = cv2.imread(pathgui, cv2.IMREAD_COLOR)\n",
    "        img_preprocessed = cv2.resize(img_preprocessed, (img_size,img_size))\n",
    "        img_preprocessed = cv2.cvtColor(img_preprocessed, cv2.COLOR_RGB2BGR)\n",
    "        list_of_images.append(img_preprocessed)\n",
    "        arr = np.array(list_of_images)\n",
    "        feature_extractor_input=VGG_model.predict(arr)\n",
    "        features_input = feature_extractor_input.reshape(feature_extractor_input.shape[0], -1)\n",
    "        prediction_RF_input = RF_model.predict(features_input)\n",
    "        prediction_RF_input_Normal = le.inverse_transform(prediction_RF_input)\n",
    "        img=img.resize((144,144)) # new width & height\n",
    "        img=ImageTk.PhotoImage(img)\n",
    "        e1 =tk.Label(root)\n",
    "        e1.grid(row=row,column=col,pady=100,padx=10)\n",
    "        e1.image = img\n",
    "        text_answer=prediction_RF_input_Normal\n",
    "        text_answer=text_answer.tolist()\n",
    "        l2 = tk.Label(root,text=text_answer,width=20,font=my_font2)  \n",
    "        l2.grid(row=row+1,column=col,pady=0,padx=10)\n",
    "        e1['image']=img # garbage collection\n",
    "        if(col==7): # start new line after third column\n",
    "            row=row+2# start wtih next row\n",
    "            col=1    # start with first column\n",
    "        else:       # within the same row \n",
    "            col=col+1 # increase to next column                 \n",
    "root.mainloop()  # Keep the window open"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
